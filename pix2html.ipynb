{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "pix2html.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true,
   "machine_shape": "hm"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BCZ0cHB696nX"
   },
   "source": [
    "# Dataset import and its preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gnvZa1BVV-IW"
   },
   "source": [
    "%%capture\n",
    "import tensorflow as tf\n",
    "import time, os\n",
    "import numpy as np\n",
    "import json\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "!pip install wandb -qqq\n",
    "import wandb\n",
    "!pip install tf-models-official"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OwBX2D_NtnEY"
   },
   "source": [
    "!wandb login"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8BnS2ydoXIq4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "%%capture\n",
    "tf.keras.utils.get_file('pix2html.zip', cache_subdir=os.path.abspath('.'), origin = 'https://raw.githubusercontent.com/psimanaitis/pix2html/main/dataset/pix2html.zip', extract = True)\n",
    "tf.keras.utils.get_file('pix2code.zip', cache_subdir=os.path.abspath('.'), origin = 'https://raw.githubusercontent.com/psimanaitis/pix2html/main/dataset/pix2code.zip', extract = True)\n",
    "\n",
    "def get_dataset_vectors(html_entries, tokenizer, input_path):\n",
    "    train_captions = []\n",
    "    img_name_vector = []\n",
    "    for x in range(len(html_entries)):\n",
    "            entry = html_entries[x]\n",
    "            full_input_path =  input_path + entry['id'] + '.jpeg'\n",
    "            img_name_vector.append(full_input_path)\n",
    "            train_captions.append(entry['content'])\n",
    "\n",
    "    train_seqs = tokenizer.texts_to_sequences(train_captions)\n",
    "    cap_vector = tf.keras.preprocessing.sequence.pad_sequences(train_seqs, padding='post')\n",
    "\n",
    "    return cap_vector, img_name_vector\n",
    "\n",
    "\n",
    "def load_dataset(dataset_name):\n",
    "    #dataset_name pix2html | pix2code\n",
    "    input_path = dataset_name + '/resized/'\n",
    "\n",
    "    with open(dataset_name + '/tokens.json', 'r') as f:\n",
    "        tokens = json.load(f)\n",
    "\n",
    "    # TODO add start end tokens for pix2code ?\n",
    "    top_k = len(tokens) + 3\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=top_k, oov_token=\"unknown\", filters='', split=\" \")\n",
    "    tokenizer.fit_on_texts(tokens)\n",
    "    tokenizer.word_index['<pad>'] = 0\n",
    "    tokenizer.index_word[0] = '<pad>'\n",
    "\n",
    "    with open(dataset_name + '/train-html.json', 'r') as f:\n",
    "        train_entries = json.load(f)\n",
    "\n",
    "    with open(dataset_name + '/train-html.json', 'r') as f:\n",
    "        test_entries = json.load(f)\n",
    "\n",
    "    train_sequences, train_images = get_dataset_vectors(train_entries, tokenizer, input_path)\n",
    "    test_sequences, test_images = get_dataset_vectors(test_entries, tokenizer, input_path)\n",
    "\n",
    "\n",
    "    return train_sequences, train_images, test_sequences, test_images, top_k, tokenizer\n",
    "\n",
    "switcher = {\n",
    "     \"vgg16\": (tf.keras.applications.VGG16(include_top=False,weights='imagenet'), tf.keras.applications.vgg16.preprocess_input, 224, 512),\n",
    "     \"vgg19\": (tf.keras.applications.VGG19(include_top=False,weights='imagenet'), tf.keras.applications.vgg19.preprocess_input, 224, 512),\n",
    "     \"EfficientNet\": (tf.keras.applications.EfficientNetB3(include_top=False,weights='imagenet'), tf.keras.applications.efficientnet.preprocess_input, 300, 1536),\n",
    "     \"inception_resnet_v2\": (tf.keras.applications.InceptionResNetV2(include_top=False,weights='imagenet'), tf.keras.applications.inception_resnet_v2.preprocess_input, 299, 1536),\n",
    "     \"resnet\": (tf.keras.applications.ResNet152V2(include_top=False,weights='imagenet'), tf.keras.applications.resnet_v2.preprocess_input, 224, 2048),\n",
    "     \"inception_v3\": (tf.keras.applications.InceptionV3(include_top=False,weights='imagenet'), tf.keras.applications.inception_v3.preprocess_input, 299, 2048),\n",
    "     \"Xception\": (tf.keras.applications.Xception(include_top=False,weights='imagenet'), tf.keras.applications.xception.preprocess_input, 299, 2048),\n",
    "}\n",
    "\n",
    "def get_load_image(imageModel):\n",
    "    image_model, preprocess_input, dimensions, cnn_features = switcher.get(imageModel)\n",
    "    def load_image(image_path):\n",
    "        img = tf.io.read_file(image_path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, (dimensions, dimensions))\n",
    "        img = preprocess_input(img)\n",
    "        return img, image_path\n",
    "\n",
    "    new_input = image_model.input\n",
    "    hidden_layer = image_model.layers[-1].output\n",
    "    image_features_extract_model = tf.keras.Model(new_input, hidden_layer)\n",
    "\n",
    "    return load_image, image_features_extract_model, cnn_features\n",
    "\n",
    "def process_images_to_npy(img_name_vector, image_features_extract_model, load_image):\n",
    "    image_dataset = tf.data.Dataset.from_tensor_slices(img_name_vector)\n",
    "    image_dataset = image_dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(16)\n",
    "    for img, path in image_dataset:\n",
    "        batch_features = image_features_extract_model(img)\n",
    "        batch_features = tf.reshape(batch_features, (batch_features.shape[0], -1, batch_features.shape[3]))\n",
    "\n",
    "        for bf, p in zip(batch_features, path):\n",
    "            path_of_feature = p.numpy().decode(\"utf-8\")\n",
    "            np.save(path_of_feature, bf.numpy())\n",
    "\n",
    "\n",
    "def map_func(img_name, html):\n",
    "    np_image_tensor = np.load(img_name.decode('utf-8')+'.npy')\n",
    "    return np_image_tensor, html\n",
    "\n",
    "\n",
    "def process_dataset(image, html, batch_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((\n",
    "        {\n",
    "            'inputs': image,\n",
    "            'dec_inputs': html[:, :-1]\n",
    "        },\n",
    "        {\n",
    "            'outputs': html[:, 1:]\n",
    "        },\n",
    "    ))\n",
    "    # TODO sort dataset by sequence length, speeds up training\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.shuffle(1000)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def get_dataset(imageModel, dataset_name, batch_size):\n",
    "    load_image, image_features_extract_model, cnn_features = get_load_image(imageModel)\n",
    "    train_sequences, train_images, test_sequences, test_images, top_k, tokenizer = load_dataset(dataset_name)\n",
    "\n",
    "    process_images_to_npy(train_images, image_features_extract_model, load_image)\n",
    "    process_images_to_npy(test_images, image_features_extract_model, load_image)\n",
    "\n",
    "\n",
    "    train_images_tensors = []\n",
    "    for entry in train_images:\n",
    "        train_images_tensors.append( np.load(entry+'.npy'))\n",
    "\n",
    "    test_images_tensors = []\n",
    "    for entry in test_images:\n",
    "        test_images_tensors.append( np.load(entry+'.npy'))\n",
    "\n",
    "    train_dataset = process_dataset(test_images_tensors, train_sequences, batch_size)\n",
    "    test_dataset = process_dataset(test_images_tensors, test_sequences, batch_size)\n",
    "\n",
    "\n",
    "    return (train_dataset, test_dataset, top_k, len(train_sequences[0]), tokenizer, cnn_features)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NqqtiAIbXVYT",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model which follow captioning transformer with staked attention architecture"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OS7VsMGSLRFi"
   },
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_masks_decoder(tar):\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "    return combined_mask"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hMXye6HqcvAE"
   },
   "source": [
    "from official.nlp.transformer.ffn_layer import FeedForwardNetwork\n",
    "from official.nlp.modeling.layers.position_embedding import RelativePositionEmbedding\n",
    "\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input((None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input((1, None, None), name=\"look_ahead_mask\")\n",
    "\n",
    "    attn1 = tf.keras.layers.MultiHeadAttention(value_dim=d_model, key_dim=d_model, num_heads=num_heads, dropout=dropout,\n",
    "                                               output_shape=d_model)(inputs, inputs, inputs, look_ahead_mask,\n",
    "                                                                     False)\n",
    "    out1 = tf.keras.layers.LayerNormalization(epsilon=1e-6, name='add_and_norm_1')(attn1 + inputs)\n",
    "\n",
    "    attn2 = tf.keras.layers.MultiHeadAttention(value_dim=d_model, key_dim=d_model, num_heads=num_heads, dropout=dropout,\n",
    "                                               output_shape=d_model)(out1, enc_outputs, enc_outputs, None,\n",
    "                                                                     False)\n",
    "    out2 = tf.keras.layers.LayerNormalization(epsilon=1e-6, name='add_and_norm_2')(attn2 + out1)\n",
    "\n",
    "    ffn_output = FeedForwardNetwork(hidden_size=d_model, filter_size=units, relu_dropout=dropout)(out2)\n",
    "    out3 = tf.keras.layers.LayerNormalization(epsilon=1e-6, name='add_and_norm_3')(ffn_output + out2)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, enc_outputs, look_ahead_mask], outputs=out3, name=name)\n",
    "\n",
    "\n",
    "def decoder(d_model, num_heads, units, target_vocab_size, max_pos_encoding, num_layers=6, dropout=0.1, name=\"decoder\"):\n",
    "    inputs = tf.keras.Input((None,), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "    embeddings = tf.keras.layers.Embedding(target_vocab_size, d_model, name='output_embeding')(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    embeddings += RelativePositionEmbedding(max_timescale=max_pos_encoding, hidden_size=d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(units=units, d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
    "                                name='decoder_layer_{}'.format(i), )(inputs=[outputs, enc_outputs, look_ahead_mask])\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, enc_outputs, look_ahead_mask], outputs=outputs, name=name)\n",
    "\n",
    "\n",
    "def transformer(vocab_size, units, d_model, num_heads, max_pos_encoding, num_layers, dropout, cnn_features, name=\"transformer\"):\n",
    "    inputs = tf.keras.Input((None, cnn_features), name=\"inputs\")\n",
    "    dec_inputs = tf.keras.Input((None,), name=\"dec_inputs\")\n",
    "\n",
    "    dec_mask = tf.keras.layers.Lambda(create_masks_decoder, output_shape=(1, None, None), name='look_ahead_mask')(\n",
    "        dec_inputs)\n",
    "\n",
    "    enc_outputs = tf.keras.layers.Dense(d_model, activation='relu', name='linear_and_relu')(inputs)\n",
    "    enc_outputs = tf.keras.layers.Dropout(rate=dropout)(enc_outputs)\n",
    "\n",
    "    dec_outputs = decoder(target_vocab_size=vocab_size, units=units, d_model=d_model, num_heads=num_heads,\n",
    "                          max_pos_encoding=max_pos_encoding, num_layers=num_layers, dropout=dropout)(\n",
    "        inputs=[dec_inputs, enc_outputs, dec_mask])\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(vocab_size, activation='softmax', name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "c7-iHkySgWxr"
   },
   "source": [
    "def custom_accuracy(real, pred):\n",
    "  casted = tf.cast(tf.argmax(pred, axis=2), tf.float32)\n",
    "  accuracies = tf.equal(real,  casted)\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  accuracies = tf.math.logical_and(mask, accuracies)\n",
    "  accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "  mask = tf.cast(mask, dtype=tf.float32)\n",
    "\n",
    "  return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_sum(loss_) / tf.reduce_sum(mask)"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_XJBCSNkxVK"
   },
   "source": [
    "# Experiments part"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_DYEh-FgjXWo"
   },
   "source": [
    "from official.nlp.optimization import create_optimizer\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "# get dataset\n",
    "batch_size = 32\n",
    "cnn_name = 'resnet' # inception_v3 inception_resnet_v2 resnet vgg16 vgg19 EfficientNet Xception'\n",
    "dataset_name =  'pix2code' # pix2code pix2html\n",
    "\n",
    "(dataset, test_dataset, top_k, sequence_length, tokenizerm, cnn_features) = get_dataset(cnn_name, dataset_name, batch_size)\n",
    "max_pos_encoding = sequence_length\n",
    "vocab_size = top_k + 1\n",
    "\n",
    "\n",
    "# get optimizer\n",
    "epochs = 5\n",
    "train_data_size = 1500\n",
    "steps_per_epoch = int(train_data_size / batch_size)\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "warmup_steps = int(epochs * train_data_size * 0.1 / batch_size)\n",
    "initial_learning_rate=2e-5\n",
    "optimizer_type = 'adamw' # 'Lamb'\n",
    "\n",
    "optimizer = create_optimizer(init_lr=initial_learning_rate,\n",
    "                     num_train_steps=num_train_steps,\n",
    "                     num_warmup_steps=warmup_steps,\n",
    "                     end_lr=0.0,\n",
    "                     optimizer_type=optimizer_type)\n",
    "\n",
    "units = 364\n",
    "d_model = 182\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "dropout = 0.1\n",
    "\n",
    "\n",
    "run = wandb.init(project=\"pix2html\", reinit=True)\n",
    "wandb.config.update({'units':units})\n",
    "wandb.config.update({'d_model':d_model})\n",
    "wandb.config.update({'num_heads':num_heads})\n",
    "wandb.config.update({'num_layers':num_layers})\n",
    "wandb.config.update({'dropout':dropout})\n",
    "wandb.config.update({'optimizer_type':optimizer_type})\n",
    "wandb.config.update({'cnn_name':cnn_name})\n",
    "wandb.config.update({'dataset_name':dataset_name})\n",
    "wandb.config.update({'max_pos_encoding':max_pos_encoding})\n",
    "wandb.config.update({'vocab_size':vocab_size})\n",
    "wandb.config.update({'epochs':epochs})\n",
    "wandb.config.update({'vocab_size':vocab_size})\n",
    "\n",
    "model = transformer(d_model = d_model,\n",
    "                    units = units,\n",
    "                    vocab_size = vocab_size,\n",
    "                    max_pos_encoding=max_pos_encoding,\n",
    "                    num_layers = num_layers,\n",
    "                    dropout = dropout,\n",
    "                    num_heads = num_heads,\n",
    "                    cnn_features= cnn_features,\n",
    "                    name='model')\n",
    "\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function,  metrics=[custom_accuracy])\n",
    "\n",
    "history = model.fit(dataset, validation_data=test_dataset, epochs=epochs, verbose=0, batch_size=batch_size, callbacks=[WandbCallback()])\n",
    "\n",
    "run.finish()\n",
    "\n",
    "# Variuos utils to visualize and save model\n",
    "# model.save('saved_model/my_model')\n",
    "# model.sumarry()\n",
    "# tf.keras.utils.plot_model(model, to_file='transformer.png', show_shapes=True, expand_nested=True, show_dtype=True, dpi=80)\n",
    "# model.save_weights(\"my_weights\")\n",
    "# model.save('saved_model/my_model') Does not work because it cannot serialise custom learning rate"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}